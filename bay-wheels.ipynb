{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "WVESlyQtz3KX"
      },
      "outputs": [],
      "source": [
        "from plotly.express import scatter_geo\n",
        "import pandas as pd\n",
        "from datetime import datetime\n",
        "from math import radians, cos, sin, asin, sqrt\n",
        "from sklearn.linear_model import LinearRegression\n",
        "import matplotlib.pyplot as plt\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "1qORFqPzz9dC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "51cbe479-6728-4213-b7de-db3ccb1f7b87"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "df1 = pd.read_csv(\"/content/drive/MyDrive/internship_and_resume_work/202210-baywheels-tripdata.csv\")\n",
        "df2 = pd.read_csv(\"/content/drive/MyDrive/internship_and_resume_work/202210-baywheels-tripdata.csv\")\n",
        "df = pd.concat([df1, df2])\n",
        "\n",
        "df = df1\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ethUMElg12rv"
      },
      "outputs": [],
      "source": [
        "#Plots every starting point onto map with bounds specified by where the locations are (SF, SJ, Berk, Oak)\n",
        "#scatter_geo(df, lat = \"start_lat\", lon = \"start_lng\", scope = \"usa\", fitbounds = \"locations\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "5bcAe_J62xLo"
      },
      "outputs": [],
      "source": [
        "\n",
        "#Creates two more columns, the start and end cities which exclude station ID and only specify city\n",
        "df[\"start_city\"] = df.start_station_id.str[0:2]\n",
        "df[\"end_city\"] = df.end_station_id.str[0:2]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9Yk_kPHh5h7w"
      },
      "outputs": [],
      "source": [
        "# All of the rides that ended in different city than started in\n",
        "df[df.start_city != df.end_city].dropna()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IykzcER-5oVw"
      },
      "outputs": [],
      "source": [
        "# How many rides started in each city\n",
        "df.groupby(\"start_city\").count()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "Fu2rwIGP8Tb7"
      },
      "outputs": [],
      "source": [
        "# Create new data frame with only the SF starting point\n",
        "sf = df[df.start_city == \"SF\"].dropna()\n",
        "# Remove rides which do not end in SF\n",
        "sf = sf.drop(sf[sf[\"end_city\"] != \"SF\"].index)\n",
        "# Remove rides which begin and end in the same station (either only unlocked bike for a few seconds or just rode in a loop back to station)\n",
        "sf = sf.drop(sf[sf.start_station_name == sf.end_station_name].index)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iDw_67z6BCjn"
      },
      "outputs": [],
      "source": [
        "# Ensures every ride start and end in a different station, should count zero\n",
        "sf[sf.start_station_name == sf.end_station_name].count()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NC2g4FIc-MRx"
      },
      "outputs": [],
      "source": [
        "# See how many rides had unique pairing of start and end coords\n",
        "sf.groupby([\"start_lat\", \"start_lng\"]).count().sort_values(\"ride_id\", ascending=False).query(\"ride_id == 1\").sum()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "k053ezEyIZ_Y"
      },
      "outputs": [],
      "source": [
        "# See stations with most amount of rides started at, #1 has ~2500\n",
        "sf.groupby(\"start_station_id\").count().sort_values(\"start_station_name\", ascending = False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "D6-Ehto6Bo4C"
      },
      "outputs": [],
      "source": [
        "# Find the mean latitude and longitude of each station\n",
        "sf.groupby([\"start_station_id\", \"start_station_name\"]).mean()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "s4HkipODCnRT"
      },
      "outputs": [],
      "source": [
        "# Create data frames containing each station and their average lat/lng coordinates as start and ends \n",
        "# NOTE: identical stations will have slightly different coords as start versus end station\n",
        "start_station_means = sf.groupby(\"start_station_id\").mean()\n",
        "end_station_means = sf.groupby(\"end_station_id\").mean()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "hfvDEiRYELgb"
      },
      "outputs": [],
      "source": [
        "# Replace exact coordinates with the average start and end coordinates of the station\n",
        "sf_with_mean_locations = pd.merge(sf.drop([\"start_lat\", \"start_lng\"], axis=1), start_station_means, on = \"start_station_id\")\n",
        "sf_with_mean_locations = pd.merge(sf_with_mean_locations.drop([\"end_lat_x\", \"end_lng_x\", \"end_lat_y\", \"end_lng_y\"], axis=1), end_station_means[[\"end_lat\", \"end_lng\"]], on = \"end_station_id\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "F5e4DMugB5WL"
      },
      "outputs": [],
      "source": [
        "# Create two columns, one containing the frequency of the start station, one for frequency of end station (NOTE frequencies will be different as start vs end for identical stations)\n",
        "start_station_frequencies = sf_with_mean_locations.groupby(\"start_station_id\").count()\n",
        "start_station_frequencies = start_station_frequencies[\"ride_id\"]\n",
        "end_station_frequencies = sf_with_mean_locations.groupby(\"end_station_id\").count()\n",
        "end_station_frequencies = end_station_frequencies[\"ride_id\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "HEVCTRWwH_NE"
      },
      "outputs": [],
      "source": [
        "# Adds column into sf data frame with frequency of the start station\n",
        "sf_with_mean_locations = pd.merge(sf_with_mean_locations, start_station_frequencies, on = \"start_station_id\")\n",
        "sf_with_mean_locations.sort_values(\"start_station_id\")\n",
        "sf_with_mean_locations = sf_with_mean_locations.rename(columns = {\"ride_id_x\" : \"ride_id\", \"ride_id_y\" : \"start_station_frequency\"})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "7SF2K4FrKH_T"
      },
      "outputs": [],
      "source": [
        "# Adds column into sf data frame with frequency of the end station\n",
        "sf_with_mean_locations = pd.merge(sf_with_mean_locations, end_station_frequencies, on = \"end_station_id\")\n",
        "sf_with_mean_locations.sort_values(\"end_station_id\")\n",
        "sf_with_mean_locations = sf_with_mean_locations.rename(columns = {\"ride_id_x\" : \"ride_id\", \"ride_id_y\" : \"end_station_frequency\"})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FaWclijF2c5C"
      },
      "outputs": [],
      "source": [
        "# Plot starting points by station, larger circles mean higher frequency of departure point\n",
        "scatter_geo(sf_with_mean_locations.sample(frac = 0.1), lat = \"start_lat\", lon = \"start_lng\", scope = \"usa\", fitbounds = \"locations\", size = \"start_station_frequency\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qCU9t6RJMj1Z"
      },
      "outputs": [],
      "source": [
        "# Plot ending points by station, larger circles mean higher frequency of ending point\n",
        "scatter_geo(sf_with_mean_locations.sample(frac = 0.1), lat = \"end_lat\", lon = \"end_lng\", scope = \"usa\", fitbounds = \"locations\", size = \"end_station_frequency\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "id": "HlotQOoByfXA"
      },
      "outputs": [],
      "source": [
        "# Takes as input two series of timestamps of the same length\n",
        "# Return a list of the same length as the input lists containing the different in seconds between corresponding timestamps in input lists\n",
        "def ride_times_series(starts, ends):\n",
        "  ride_times = []\n",
        "  for i in range(len(starts)):\n",
        "    ride_times.append(datetime.strptime(ends[i][2:], \"%y-%m-%d %H:%M:%S\").timestamp() - datetime.strptime(starts[i][2:], \"%y-%m-%d %H:%M:%S\").timestamp())\n",
        "  return ride_times"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "id": "JdUG1se2y7Mb"
      },
      "outputs": [],
      "source": [
        "# Adds column into dataframe containing the ride time in seconds\n",
        "sf_with_mean_locations[\"ride_time\"] = ride_times_series(sf_with_mean_locations.started_at, sf_with_mean_locations.ended_at)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "id": "56kzm5XGpi0A"
      },
      "outputs": [],
      "source": [
        "# Takes as input floats representing two sets of coordinates\n",
        "# Returns float representing haversine distance between the two, or the angular distance between two points on the surface of a sphere\n",
        "# 3956 represents the radius of the Earth\n",
        "def haversine(lon1, lat1, lon2, lat2):\n",
        "    # convert decimal degrees to radians \n",
        "    lon1, lat1, lon2, lat2 = map(radians, [lon1, lat1, lon2, lat2])\n",
        "\n",
        "    # haversine formula \n",
        "    dlon = lon2 - lon1 \n",
        "    dlat = lat2 - lat1 \n",
        "    a = sin(dlat/2)**2 + cos(lat1) * cos(lat2) * sin(dlon/2)**2\n",
        "    c = 2 * asin(sqrt(a)) \n",
        "    r = 3956 # Radius of earth in miles\n",
        "    return c * r"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "id": "Tz2skEYrwhcV"
      },
      "outputs": [],
      "source": [
        "# Takes as input four series corresponding to starting and ending coordinates for all rides, all series are identical length\n",
        "# Return a list of the same length as the input lists containing the haversine distance between start and end coordinates in corresponding input lists\n",
        "def haversine_series(start_lngs, start_lats, end_lngs, end_lats):\n",
        "  distance_series = []\n",
        "  for i in range(len(start_lngs)):\n",
        "    distance_series.append(haversine(start_lngs[i], start_lats[i], end_lngs[i], end_lats[i]))\n",
        "  return distance_series"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "id": "wAOzk51vj_lu"
      },
      "outputs": [],
      "source": [
        "# Adds column into data frame containing distance between start and end stations\n",
        "sf_with_mean_locations[\"haversine_distance\"] = haversine_series(sf_with_mean_locations.start_lng, sf_with_mean_locations.start_lat, sf_with_mean_locations.end_lng, sf_with_mean_locations.end_lat)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "id": "ufwTL_uqBj94"
      },
      "outputs": [],
      "source": [
        "# Takes as input series containing whether each bikes user was electric or classic\n",
        "# Returns list containing a 1 if a bike was electric, and 0 if the bike was a classic\n",
        "def bike_types(bikes):\n",
        "  bike_types = []\n",
        "  for i in range(len(bikes)):\n",
        "    if (bikes[i] == \"electric_bike\"):\n",
        "      bike_types.append(1)\n",
        "    else:\n",
        "      bike_types.append(0)\n",
        "  return bike_types\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "id": "VDeJZGdPxfLI"
      },
      "outputs": [],
      "source": [
        "# Add a column into dataframe using ones and zeroes to representing bike type used for the ride\n",
        "sf_with_mean_locations[\"bike_type\"] = bike_types(sf_with_mean_locations.rideable_type)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "id": "_J7oVw7iCu9B"
      },
      "outputs": [],
      "source": [
        "# Takes as input series containing whether each rider was a member or casual user\n",
        "# Returns list containing a 1 if a user was a member, and 0 if the user was a casual user\n",
        "def user_types(types):\n",
        "  user_types = []\n",
        "  for i in range(len(types)):\n",
        "    if (types[i] == \"member\"):\n",
        "      user_types.append(1)\n",
        "    else:\n",
        "      user_types.append(0)\n",
        "  return user_types"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "id": "LWCBhwZaDFZY"
      },
      "outputs": [],
      "source": [
        "# Add a column into dataframe using ones and zeroes to representing user type for the ride\n",
        "sf_with_mean_locations[\"user_type\"] = user_types(sf_with_mean_locations.member_casual)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def make_graph(x, y, x_name, y_name, graph_name):\n",
        "  # plotting the points \n",
        "  plt.scatter(x, y, marker = \".\", s = 0.5)\n",
        "  # naming the x axis\n",
        "  plt.xlabel(x_name)\n",
        "  # naming the y axis\n",
        "  plt.ylabel(y_name)\n",
        "  # giving a title to my graph\n",
        "  plt.title(graph_name)\n",
        "  # function to show the plot\n",
        "  plt.show()"
      ],
      "metadata": {
        "id": "ipifpbkDbMMU"
      },
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sf_with_mean_locations.sort_values(\"haversine_distance\")"
      ],
      "metadata": {
        "id": "KQWEqkYGTw9i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sf_with_mean_locations[\"avg_mile\"] = sf_with_mean_locations.ride_time / sf_with_mean_locations.haversine_distance"
      ],
      "metadata": {
        "id": "IO7yOq0nOvJM"
      },
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sf_with_mean_locations = sf_with_mean_locations.drop(sf_with_mean_locations[sf_with_mean_locations.ride_time > 10000].index)\n"
      ],
      "metadata": {
        "id": "yi9AfBl_beuo"
      },
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "make_graph(sf_with_mean_locations.haversine_distance, sf_with_mean_locations.ride_time, \"Distance\", \"Ride Time\", \"Distance vs. Ride Time\")"
      ],
      "metadata": {
        "id": "ruPJFu7EbDEH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eqnVh27aSsgV"
      },
      "outputs": [],
      "source": [
        "# Keep only data with average seconds/mile within two standard deviations of the mean\n",
        "#Remove largest outliers\n",
        "sf_with_mean_locations = sf_with_mean_locations.drop(sf_with_mean_locations[sf_with_mean_locations.ride_time > 2000].index)\n",
        "mean_mile_rate = sf_with_mean_locations.avg_mile.mean()\n",
        "std_mile_rate = sf_with_mean_locations.avg_mile.std()\n",
        "print(mean_mile_rate, std_mile_rate)\n",
        "sf_with_mean_locations = sf_with_mean_locations.drop(sf_with_mean_locations[sf_with_mean_locations.avg_mile < (mean_mile_rate - 2 * std_mile_rate)].index)\n",
        "sf_with_mean_locations = sf_with_mean_locations.drop(sf_with_mean_locations[sf_with_mean_locations.avg_mile > (mean_mile_rate + 2 * std_mile_rate)].index)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "kpEkqZVKOd0a"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EkZnByemDEmO"
      },
      "outputs": [],
      "source": [
        "INPUTS = sf_with_mean_locations[[\"user_type\", \"bike_type\", \"haversine_distance\", \"start_station_name\", \"end_station_name\"]].copy()\n",
        "one_hot_encoded_input = pd.get_dummies(INPUTS, columns = [\"start_station_name\", \"end_station_name\"])\n",
        "one_hot_encoded_input\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0DWsgcYnXFLK"
      },
      "outputs": [],
      "source": [
        "outputs = sf_with_mean_locations[\"ride_time\"]\n",
        "outputs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {
        "id": "_-yWBq40CcxU"
      },
      "outputs": [],
      "source": [
        "ride_time_model = LinearRegression().fit(one_hot_encoded_input, outputs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "F2tM4kE1QVdQ"
      },
      "outputs": [],
      "source": [
        "# Results of the model: \n",
        "\n",
        "# Obtain the coefficient of determination by calling the model with the score() function, then print the coefficient:\n",
        "r_sq = ride_time_model.score(one_hot_encoded_input, outputs)\n",
        "print('Coefficient of Determination:', r_sq)\n",
        "\n",
        "# Print the Intercept:\n",
        "print('intercept:', ride_time_model.intercept_)\n",
        "\n",
        "# Print the Slope:\n",
        "print('slope:', ride_time_model.coef_)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {
        "id": "8POWVSPtGcla"
      },
      "outputs": [],
      "source": [
        "sf_with_mean_locations[\"predictions\"] = ride_time_model.predict(one_hot_encoded_input)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {
        "id": "F8_NaV4vG_8M"
      },
      "outputs": [],
      "source": [
        "sf_with_mean_locations[\"prediction_diff\"] = abs(sf_with_mean_locations.ride_time - sf_with_mean_locations.predictions)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aKgz5X9cHCcO"
      },
      "outputs": [],
      "source": [
        "sf_with_mean_locations.sort_values(\"prediction_diff\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "make_graph(sf_with_mean_locations.haversine_distance, sf_with_mean_locations.ride_time, \"Distance\", \"Ride Time\", \"Distance vs. Ride Time\")"
      ],
      "metadata": {
        "id": "43hb-3QHaE1X"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}